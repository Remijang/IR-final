[
    {
        "type": "text",
        "text": "A.1.3 ARM Cortex-A15 ",
        "text_level": 1,
        "page_idx": 738
    },
    {
        "type": "text",
        "text": "The ARM $\\textsuperscript { \\textregistered }$ Cortex $\\textsuperscript { \\textregistered }$ -A15 is the latest ARM processor to be released as of early 2013. This processor is targeted towards high performance applications. ",
        "page_idx": 738
    },
    {
        "type": "text",
        "text": "Overview ",
        "text_level": 1,
        "page_idx": 738
    },
    {
        "type": "text",
        "text": "The Cortex-A15 processor is much more complicated, and much more powerful than the CortexM3 and Cortex-A8. Instead of using an inorder core, it uses a 3-issue superscalar out-of-order core. It also has a deeper pipeline. Specifically, it has a 15 stage integer pipeline, and a 17-25 stage floating point pipeline. The deeper pipeline allows it to run at a significantly higher frequency (1.5 \u2013 2.5 GHz). Additionally, it fully integrates VFP and NEON units on the core instead of having them as separate execution units. Like server processors, it is designed to access a large amount of memory. It can support a 40-bit physical address, which means that it can address up to 1 TB of memory using the latest AMBA bus protocol that supports system level coherence. The Cortex-A15 is designed to run modern operating systems, and virtual machines. Virtual machines are special programs that can help run multiple operating systems concurrently on the same processor. They are used in server and cloud computing environments to support users with varying software requirements. The Cortex-A15 incorporates sophisticated power management techniques that dynamically shut off parts of the processor when they are not being used. ",
        "page_idx": 738
    },
    {
        "type": "text",
        "text": "Another iconic feature of the Cortex-A15 processor is that it is a multicore processor. It organizes 4 cores per cluster, and we can have multiple clusters per chip. The Snoop Control Unit provides coherency within a cluster. The AMBA4 specification defines the protocol for supporting cache and system level coherence across clusters. Additionally, the AMBA4 bus also supports synchronization operations. The memory system is also faster and more reliable. The Cortex-A15\u2019s memory system uses SECDED (single error correct, double error detect) error control codes. ",
        "page_idx": 738
    },
    {
        "type": "text",
        "text": "Design of the Pipeline ",
        "page_idx": 739
    },
    {
        "type": "image",
        "img_path": "images/8aa019d8d064175acb5cba07eb4d6e31b611733ffa764df8838a011d3f6e8ba4.jpg",
        "img_caption": [
            "Figure A.4: Overview of the ARM Cortex A-15 processor, source [arm, d]. Reproduced with permission from ARM Limited. Copyright c ARM Limited (or its affiliates). "
        ],
        "img_footnote": [],
        "page_idx": 739
    },
    {
        "type": "text",
        "text": "Figure A.4 shows an overview of the pipeline of a Cortex-A15 core. We have 5 fetch stages. Here, fetch is more complicated because, the Cortex-A15 has a sophisticated branch predictor that can handle many types of branch instructions. The decode, rename, and instruction dispatch units are pipelined across 7 stages. Recall from our discussion in Section 10.11.4 that the register rename unit, and instruction window are critical to the performance of out-of-order processors. Their role is to find sets of instructions that are ready to execute in a given cycle. ",
        "page_idx": 739
    },
    {
        "type": "text",
        "text": "The Cortex-A15 has several execution pipelines. The integer ALU, and branch pipelines require 3 cycles each. However, the multiply and load/store pipelines are longer. Unlike other ARM processors that treat the NEON/VFP units as a physically separate unit, the Cortex-A15 integrates it on the core. It is a part of the out-of-order pipeline. Let us now look at the pipeline in some more detail (refer to Figure A.5). ",
        "page_idx": 739
    },
    {
        "type": "text",
        "text": "The Cortex-A15 core\u2019s (the same features are available in the branch predictor of the CortexA8 also) branch predictor contains a predictor for direct branches, a predictor for indirect branches, and a predictor to predict the return address. The indirect branch predictor tries to predict the branch target-based on the PC of the branch instruction. It has a 256 entry buffer that is indexed by the history of a given branch, and its PC. We do not actually need sophisticated branch prediction logic to predict the target of a return instruction. A simpler method is to record the return address whenever we call a function, and push it on a stack (referred to as the return address stack(RAS)). Since function calls exhibit last in-first out behavior, we need to simply pop the RAS and get the value of the return address while returning from a function. Lastly, to support wider issue widths the fetch unit is designed to fetch 128 bits at once from the instruction cache. ",
        "page_idx": 739
    },
    {
        "type": "text",
        "text": "The loop buffer (present in the Cortex-A8 also) is a very interesting addition to the decode stage. Let us assume that we are executing a set of instructions in a loop, which is most often the case. In any other processor, we need to fetch the instructions in a loop repeatedly, and decode them. This process wastes energy, and memory bandwidth. We can optimize this process by saving all the decoded instruction packets in a loop buffer such that we can bypass the fetch and decode units altogether while executing a loop. The register rename stage can thus get instructions from the decode unit or the loop buffer. ",
        "page_idx": 739
    },
    {
        "type": "image",
        "img_path": "images/868f09372494775c154a53ab45feb7c6f9d045b5574b2ca17eac0c05bee07db8.jpg",
        "img_caption": [
            "Figure A.5: The pipeline of the ARM Cortex A-15 processor , source [arm, c]. Reproduced with permission from ARM Limited. Copyright $\\circledcirc$ ARM Limited (or its affiliates). "
        ],
        "img_footnote": [],
        "page_idx": 740
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 740
    },
    {
        "type": "text",
        "text": "The core maintains a reorder buffer (ROB) (see Section 10.11.4) that contains the results of all the instructions. Recall that entries in the ROB are allocated in program order. The rename stage maps operands to entries in the ROB (referred to as the result queue in ARM\u2019s documentation). For example, if instruction 3 needs a value that is going to be produced by instruction 1, then the corresponding operand is mapped to the ROB entry of instruction 1. All the instructions subsequently enter the instruction window and wait for their source operands to be ready. Once they are ready, they are dispatched to the corresponding pipelines. The Cortex-A15 has 2 integer ALUs, 1 branch unit, 1 multiply unit, and 2 load/store units. The NEON/VFP unit can accept 2 instructions per cycle. ",
        "page_idx": 740
    },
    {
        "type": "text",
        "text": "The load/store unit has a 4 stage pipeline. For ensuring precise exceptions stores are only issued to the memory system, when the instruction reaches the head of the ROB (there are no earlier instructions in the pipeline). Meanwhile, any load operation that has a store operation to the same address in the pipeline gets its value through a forwarding path. Both the L1 caches (instruction and data) are typically 32 KB each. ",
        "page_idx": 741
    },
    {
        "type": "text",
        "text": "The Cortex-A15 processor supports a large L2 cache (up to 4 MB). It is a 16-way set associative cache with an aggressive prefetcher. The L1 caches, and the L2 cache are a part of the cache coherence protocol. The Cortex-A15 uses a directory-based MESI protocol. The L2 cache contains a snoop tag array that maintains a copy of all the directories at the L1 level. If an I/O operation wishes to modify some line, then the L2 cache uses the snoop tag array to find if the line resides in any L1 cache. If any L1 cache contains a copy of the line, then this copy is invalidated. Likewise, if there is a DMA read operation, then the L2 controller fetches the line from the L1 cache that contains a copy of it. It is additionally possible to extend this protocol to support L3 caches, and a host of peripherals. ",
        "page_idx": 741
    }
]