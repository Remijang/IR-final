A.2.1 AMD Bobcat

Overview

The Bobcat processor (original paper [Burgess et al., 2011]) was designed to operate within a 10-15W power budget. Within this power budget, the designers of Bobcat were able to implement many complex architectural features in the processor. For example, Bobcat uses a fairly elaborate 2 issue out-of-order pipeline. Bobcat’s pipeline uses a sophisticated branch predictor, and is designed to fetch 2 instructions in the same cycle. It can subsequently decode them at that rate and convert them to complex micro-ops (Cops). A complex micro-op (Cop) in AMD’s terminology is a CISC like instruction that can read and write to memory. The Cops are subsequently sent to the instruction queue, renaming engine, and scheduler.

The scheduler selects instructions out-of-order and dispatches them to the ALU, memory address generation units, and the load/store units. The load/store unit also sends requests to the memory system out-of-order in the interest of performance. Hence, we can readily conclude that Bobcat supports a weak memory model. Along with sophisticated micro-architectural features, the Bobcat processor also supports SIMD instruction sets (up to SSE 4), methods to automatically save the processor state in memory, and 64-bit instructions. To ensure that the power consumption of the processor is within limits, Bobcat contains numerous power saving optimizations. One such prominent mechanism is known as clock gating. Here, the clock signal is set to a logical 0 for units that are unused. This ensures that there are no signal transitions in the unused units, and consequently there is no dissipation of dynamic power. The Bobcat processor also uses pointers to data as much as possible, and tries to avoid copying data across different locations in the processor. Let us now look at the design of the pipeline in some more detail.

Design of the Pipeline

Figure A.6 shows a block diagram of the pipeline of the AMD Bobcat processor. A distinguishing feature of the Bobcat processor is the fairly sophisticated branch predictor. We need to first predict if an instruction is a branch or not. This is because, there is no way of finding this out quickly in the x86 ISA. If an instruction is predicted to be a branch, we need to compute its outcome (taken/not taken), and the target. AMD uses an advanced pattern-matching-based proprietary algorithm for branch prediction. After branch prediction, the fetch engine fetches 32 bytes from the i-cache at once, and sends it to an instruction buffer.

The decoder considers 22 instruction bytes at a time, and tries to demarcate instruction boundaries. This is a slow and computationally intensive process because x86 instruction lengths can have a lot of variability. Larger processors typically cache this information such that decoding an instruction for the second time is easier. Since the decode throughput of Bobcat is only limited to 2 instructions, it does not have this feature. Now, most pairs of x86 instructions fit within 22 bytes, and thus the decoder can most of the time extract the contents of both the x86 instructions. The decoder typically converts each x86 instruction to 1-2 Cops. For some infrequently used instructions, it replaces the instruction with a microcode sequence.

Subsequently, the Cops are added to a 56 entry reorder buffer (ROB). Bobcat has two schedulers. The integer scheduler has 16 entries, and the floating point scheduler has 18 entries. The integer scheduler selects two instructions for execution every cycle. The integer pipeline has two ALUs, and two address generation units (1 for load, and 1 for store). The floating point pipeline can also execute two Cops per cycle with some restrictions.

The load-store unit in the processor forwards values from store to load instructions in the pipeline whenever possible. Bobcat has 32 KB (8-way associative) L1 data and instruction caches. They are connected to a 512 KB L2 cache (16-way set associative). The bus interface connects the L2 cache to the main memory, and system bus.

Let us now consider the timing of the pipeline. The Bobcat integer pipeline is divided into 16 stages. Because of the deep pipeline, it is possible to clock the core at frequencies between 1-2 GHz. The Bobcat pipeline has 6 fetch cycles, and 3 decode cycles. The last 3 fetch cycles are overlapped with the decode cycles. The renaming engine, and scheduler take 4 more cycles. For most integer instructions, we require 1 cycle to read the register file, 1 cycle to access the ALU, and 1 more cycle to write the results back to the register file. The floating point pipeline has 7 additional stages, and the load-store unit requires 3 additional stages for address generation, and data cache access.