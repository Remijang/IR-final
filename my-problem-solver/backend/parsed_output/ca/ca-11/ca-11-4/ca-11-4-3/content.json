[
    {
        "type": "text",
        "text": "11.4.3 Implementation of Virtual Memory with Paging ",
        "text_level": 1,
        "page_idx": 548
    },
    {
        "type": "text",
        "text": "To balance the requirements of the processor, operating system, compiler, and programmer we need to design a translation system that can translate the address generated by a process into an address that the memory system can use. By using a translator, we can satisfy the requirements of the programmer/compiler, who need virtual memory, and the processor/memory system, who need physical memory. A translation system is similar to what a translator in real life would do. For example, if we have a Russian delegation visiting Dubai, then we need a translator who can translate Russian to Arabic. Both the sides can then speak their own language, and thus be happy. A conceptual diagram of the translation system is shown in Figure 11.20. ",
        "page_idx": 548
    },
    {
        "type": "image",
        "img_path": "images/9cf32f022ebcf689443e04f57ec15ff2ad36ba31c2b5aff2a151e02f5dcfe670.jpg",
        "img_caption": [
            "Figure 11.20: Address translation system "
        ],
        "img_footnote": [],
        "page_idx": 548
    },
    {
        "type": "text",
        "text": "Let us now try to design this address translation system. Let us first succinctly list the requirements that a program and compiler place on the nature of virtual memory. ",
        "page_idx": 548
    },
    {
        "type": "text",
        "text": "1. Any address in the range of valid addresses should be accessible. For example, in a Linuxbased machine, a process\u2019s virtual memory size is limited to 3 GB. Hence, it should be possible to access any address in this range.   \n2. The virtual memory should be perceived as one contiguous memory space where the entire space is available to the program. ",
        "page_idx": 548
    },
    {
        "type": "text",
        "text": "3. Unless explicitly desired by the program, there should be no interference from any other program. ",
        "page_idx": 549
    },
    {
        "type": "text",
        "text": "Here are the requirements from the side of the memory system. ",
        "page_idx": 549
    },
    {
        "type": "text",
        "text": "1. Different programs should access non-overlapping sets of addresses.   \n2. A program cannot be allotted a large continuous chunk of memory addresses. This will cause a high degree of wastage in space due to fragmentation.   \n3. If the total amount of physical memory is less than the size of the virtual memory, then there should be additional storage space available to support programs that require more space than the total amount of physical memory. ",
        "page_idx": 549
    },
    {
        "type": "text",
        "text": "Let us now try to satisfy these requirements by designing a translation system that takes an address as specified in the program, and translates it to a real address that can be presented to the memory system. The address specified in the program is known as the virtual address, and the address sent to the memory system is known as the physical address. ",
        "page_idx": 549
    },
    {
        "type": "text",
        "text": "Definition 113 ",
        "text_level": 1,
        "page_idx": 549
    },
    {
        "type": "text",
        "text": "Virtual Address An address specified by the program in the virtual address space. ",
        "page_idx": 549
    },
    {
        "type": "text",
        "text": "Physical Address An address presented to the memory system after address translation. ",
        "page_idx": 549
    },
    {
        "type": "text",
        "text": "We can trivially achieve a translation system by uniquely mapping every virtual address to a physical address at the level of every byte or memory word (4 bytes). In this case, the program perceives one contiguous memory space. Secondly, we need to only map those virtual addresses that are actually used by the program. If a program actually requires 3 MB of space, then we end up using only 3 MB of physical memory. Whenever, the process requires a new set of bytes that have not been already mapped, a smart memory management unit can allocate new space in physical memory. Lastly, note that it is necessary for every memory access to pass through this translation system. ",
        "page_idx": 549
    },
    {
        "type": "text",
        "text": "Even though our basic translation system satisfies all our requirements, it is not efficient. We need to maintain a large table that maps every byte in the virtual address space to a byte in the physical address space. This mapping table between the virtual and physical addresses will be very large and slow. It is also not a very power efficient scheme. Secondly, our scheme does not take advantage of spatial and temporal locality. Hence, let us try to make our basic system more efficient. ",
        "page_idx": 549
    },
    {
        "type": "text",
        "text": "Pages and Frames ",
        "page_idx": 549
    },
    {
        "type": "text",
        "text": "Definition 114 ",
        "text_level": 1,
        "page_idx": 550
    },
    {
        "type": "text",
        "text": "Page It is a block of memory in the virtual address space. ",
        "page_idx": 550
    },
    {
        "type": "text",
        "text": "Frame It is a block of memory in the physical address space. A page and frame have the same size. ",
        "page_idx": 550
    },
    {
        "type": "text",
        "text": "Page Table It is a mapping table that maps the address of each page to an address of a frame. Each process has its own page table. ",
        "page_idx": 550
    },
    {
        "type": "text",
        "text": "Instead of translating addresses at the granularity of bytes, let us translate addresses at the granularity of larger blocks. This will reduce the amount of state that we need to maintain, and also take advantage of spatial locality. Let us define a block of memory in the virtual address space and call it a page. Similarly, let us define a block of the same size in the physical address space and call it a frame. The size of a page or a frame is typically 4 KB. Secondly, note that the virtual address space is unique to each process; whereas, the physical address space is the same for all processes. For each process, we need to maintain a mapping table that maps each page to a frame. This is known as the page table. A page table can either be implemented in hardware or in software. A hardware implementation of the page table has dedicated structures to store the mapping between virtual and physical addresses. The lookup logic is also in hardware. In the case of a software implementation, the mappings are stored in a dedicated region of the physical address space. In most processors that use software page tables, the lookup logic is also in hardware. They typically do not use custom routines in software to lookup page tables because this approach is slow and complicated. Since the lookup logic of page tables is primarily in hardware, the design of page tables needs to be relatively simple. The page tables that we describe in the next few sections are oblivious to how they are implemented (software or hardware). ",
        "page_idx": 550
    },
    {
        "type": "text",
        "text": "Let us consider a 32-bit memory address. We can now split it into two parts. If we consider a 4 KB page, then the lower 12 bits specify the address of a byte in a page (reason: $2 ^ { 1 2 } = 4 0 9 6 = 4 K B$ ). This is known as the offset. The upper 20 bits specify the page number (see Figure 11.21). Likewise, we can split a physical address into two parts \u2013 frame number and offset. The process of translation as shown in Figure 11.21, first replaces the 20 bit page number with an equivalent 20 bit frame number. Then it appends the 12 bit offset to the physical frame number. ",
        "page_idx": 550
    },
    {
        "type": "text",
        "text": "A Single Level Page Table ",
        "text_level": 1,
        "page_idx": 550
    },
    {
        "type": "text",
        "text": "Figure 11.22 shows a basic page table that contains $2 ^ { 2 0 }$ $( \\approx 1 , 0 0 0 , 0 0 0 )$ rows. Each row is indexed by the page number, and it contains the corresponding 20 bit (2.5 byte) frame number. The total size of the table is thus 2.5 MB. If we have 200 processes in the system at any point of time, then we need to waste 500 MB of precious memory for just saving page tables! If our total main memory is 2 GB, then we are spending $2 5 \\%$ of it in saving page tables, which appears to be a big waste of space. Secondly, it is possible that in some systems, we might not even have ",
        "page_idx": 550
    },
    {
        "type": "image",
        "img_path": "images/4ec7ccbb1a1fb1c17bfc58f8eb3fc73b1a5e5862849a4e445f936aa984e31ef2.jpg",
        "img_caption": [
            "Figure 11.21: Translation of a virtual to a physical address "
        ],
        "img_footnote": [],
        "page_idx": 551
    },
    {
        "type": "image",
        "img_path": "images/d696b101b2c8f6e39a3213bcea492c477a181a89bdb4a6d94f4352a40667ccf7.jpg",
        "img_caption": [
            "Figure 11.22: A single level page table "
        ],
        "img_footnote": [],
        "page_idx": 551
    },
    {
        "type": "text",
        "text": "500 MB of main memory available. In this case, we cannot support 200 live processes at the same time. We need to look for better solutions. ",
        "page_idx": 551
    },
    {
        "type": "text",
        "text": "Let us now look for insights that might help us reduce the amount of storage. We start out by noticing that large parts of the virtual address space of a process are actually empty. In a 32-bit system, the size of the virtual address space is 4 GB. However, large programs do not use more than 100 MB. There is a massive empty region between the stack and the heap sections in the memory map, and thus it is not necessary to allocate space for mapping this region. Ideally, the number of entries in the page table should be equal to the number of pages actually used by a process rather than the theoretically maximum number of pages a process can use. If a process uses only 400 KB of memory space, then ideally its page table should just contain 100 entries. Let us design a two level page table to realize this goal. ",
        "page_idx": 551
    },
    {
        "type": "image",
        "img_path": "images/fe994c35c8fe92471dd26e1c04e2eb037899631793db8e3d73dcfacd321f2878.jpg",
        "img_caption": [
            "Figure 11.23: A two level page table "
        ],
        "img_footnote": [],
        "page_idx": 552
    },
    {
        "type": "text",
        "text": "Two-Level Page Table ",
        "text_level": 1,
        "page_idx": 552
    },
    {
        "type": "text",
        "text": "Let us further split a page number into two equal parts. We split the 20 bits into two parts containing 10 bits each as shown in Figure 11.23. The upper 10 bits are used to access a toplevel page table known as the primary page table. Each entry in the top-level page table points to a secondary page table. Subsequently, each secondary page table is indexed by the lower 10 bits of the page number. An entry in the secondary page table contains the frame number. If no addresses map to a given entry in the primary page table, then it does not point to a secondary page table, and thus there is no need to allocate space for it. In a typical program, most of the entries in the primary page table are expected to be empty. Let us now calculate the size of this structure. ",
        "page_idx": 552
    },
    {
        "type": "text",
        "text": "The primary page table contains 1024 entries, where each entry is 10 bits long. The total size is 1.25 KB (10 bits = 1.25 bytes). Let the number of secondary page tables be $N$ . Each secondary page table contains 1024 entries, where each entry is 20 bits long. Therefore, the size of each secondary page table is 2.5 KB, and the total storage requirement is $( 1 . 2 5 + 2 . 5 \\times N )$ KB. Because of spatial locality in a program, $N$ is not expected to be a large number. Let us consider a program that has a memory footprint of 10 MB. It contains roughly 2500 pages. Each secondary page table can map at the most 1024 pages (4 MB of data). It is highly likely that this program might map to only three secondary page tables. Two page tables will contain the mappings for the text, data, and heap sections, and one page table will contain the mappings for the stack section. In this case, the total storage requirement for the page tables will be equal to 8.75 KB, which is very reasonable. Even, if we require double the number of secondary page tables because of lower spatial locality in the memory map, then also the total storage requirement is equal to 16.25 KB. This is an order of magnitude better than a single level page table that required 2.5 MB of storage per process. Hence, two level page tables are used in most commercial systems. ",
        "page_idx": 552
    },
    {
        "type": "text",
        "text": "Inverted Page Table ",
        "text_level": 1,
        "page_idx": 553
    },
    {
        "type": "image",
        "img_path": "images/0d4f7d9c4581997e5b4be63fedfa109b074c8438c13e6ba66021e349a85f4d23.jpg",
        "img_caption": [
            "Figure 11.24: Inverted page table "
        ],
        "img_footnote": [],
        "page_idx": 553
    },
    {
        "type": "text",
        "text": "Some processors such as the Intel Itanium, and PowerPC 603, use a different design for a page table. Instead of addressing the page table using the page number, they address it using the frame number. In this case, there is one page table for the entire system. Since one frame is typically uniquely mapped to a page in a process, each entry in this inverted page table contains the process id, and page number. Figure 11.24(a) shows the structure of an inverted page table. The main advantage of an inverted page table is that we do not need to keep a separate page table for each process. We can save space if there are a lot of processes, and the size of physical memory is small. ",
        "page_idx": 553
    },
    {
        "type": "text",
        "text": "The main difficulty in inverted page tables is in performing a lookup for a virtual address. Scanning all the entries is a very slow process, and is thus not practical. Hence, we need to have a hashing function that maps the \u27e8 process id, page number \u27e9 pair to an index in a hash table. This index in the hash table needs to point to an entry in the inverted page table. Since multiple virtual addresses can point to the same entry in the hash table, it is necessary to verify that the process id, page number pair matches that stored in the entry in the inverted page table. Readers can refer to [Cormen et al., 2009] for a detailed explanation of the theory and operation of hash tables. ",
        "page_idx": 553
    },
    {
        "type": "text",
        "text": "We show one scheme for using an inverted page table in Figure 11.24(b). After computing a hash of the page number, and process id pair, we access a hash table indexed by the contents of the hash. The contents of the hash table entry point to a frame, $f$ , that might map to the given page. However, we need to verify, since it is possible that the hash function maps multiple pages to the same frame. Subsequently, we access the inverted page table, and access the entry, $f$ . An entry of the inverted page table, contains the page number, process id pair that is mapped to the given entry (or given frame). If we find that the contents do not match, then we keep searching for the page number, process id pair in the subsequent $K$ entries. This method is called linear probing (see [Cormen et al., 2009]), where we keep searching in the target data structure till we get a match. If we do not get a match within $K$ entries, then we may conclude that the page is not mapped. We need to then create a mapping, by evicting an entry (similar to caches), and writing it to a dedicated region in main memory that buffers all the entries that are evicted from the inverted page table. We need to always guarantee that the entry pointed to by the hash table, and the actual entry that contains the mapping, do not differ by more than $K$ entries. If we do not find any free slots, then we need to evict an entry. ",
        "page_idx": 553
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 554
    },
    {
        "type": "text",
        "text": "An astute reader might argue that we can directly use the output of the hashing engine to access the inverted page table. Typically, we add accessing the hash table as an intermediate step because it allows us to have better control over the set of frames that are actually used. Using this mechanism, it is possible to disallow mappings for certain frames. These frames can be used for other purposes. Lastly, we need to note that the overhead of maintaining, and updating hash tables outweighs the gains in having a system-wide page table. Hence, an inverted page table is typically not used in commercial systems. ",
        "page_idx": 554
    },
    {
        "type": "text",
        "text": "Translation Lookaside Buffer (TLB) ",
        "text_level": 1,
        "page_idx": 554
    },
    {
        "type": "text",
        "text": "For every single memory access it is necessary to look up the page table for translating the virtual address. The page table itself is stored in physical memory. Hence, we need to do a separate memory access to read the corresponding entry of the page table. This approach doubles the number of memory accesses, and is thus very inefficient. However, we can minimize the number of extra memory accesses by maintaining a small cache of mappings in the processor. We typically use a structure known as the Translation Lookaside Buffer (TLB) that is a small fully associative cache. A TLB contains 32-64 entries. Each entry is indexed by the page number, and contains the corresponding frame number. ",
        "page_idx": 554
    },
    {
        "type": "text",
        "text": "Once a memory address is calculated in the EX stage of the pipeline. It is sent to the TLB. The TLB is a very fast structure, and typically its access time is a fraction of a cycle. If there is a TLB hit, then the physical address is ready by the time we reach the memory access $( M A )$ stage. The $M A$ stage of the pipeline can then issue the read/write request to the memory system using the physical address obtained from the TLB. However, if there is a TLB miss, then the pipeline needs to stall, and the page table needs to be accessed. This is a slow process and takes tens of cycles. Fortunately, the hit rate of a TLB is very high $\\approx 9 9 \\%$ ) in most programs because of two reasons. First, programs have a high degree of temporal locality. Second, a 64 entry TLB covers 256 KB of the virtual address space (assuming a 4 KB page). The working set of most programs fits within this limit for small windows of time. ",
        "page_idx": 554
    }
]