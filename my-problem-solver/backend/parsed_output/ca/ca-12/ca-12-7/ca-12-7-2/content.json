[
    {
        "type": "text",
        "text": "12.7.2 Further Reading ",
        "text_level": 1,
        "page_idx": 635
    },
    {
        "type": "text",
        "text": "The reader should start by reading the relevant sections in advanced textbooks on computer architecture. The first recommendation is the textbook written by your author on advanced computer architecture [Sarangi, ]. Other textbooks [Culler et al., 1998, Hwang, 2003, Baer, 2010, Jacob, 2009] in this space can also be consulted, especially the book by Jacob [Jacob, 2009] for details of the memory system. ",
        "page_idx": 635
    },
    {
        "type": "text",
        "text": "For parallel programming, the reader can start with Michael Quinn\u2019s book on parallel programming with OpenMP and MPI [Quinn, 2003]. The formal MPI specifications are available at http://www.mpi-forum.org. For an advanced study of cache coherence the reader can start with the survey on coherence protocols by Stenstrom [Stenstrom, 1990], and then look at one of the earliest practical implementations [Borrill, 1987]. The most popular reference for memory consistency models is a tutorial by Adve and Gharachorloo [Adve and Gharachorloo, 1996], and a paper published by the same authors [Gharachorloo et al., 1992]. For a different perspective on memory consistency models in terms of ordering, and atomicity, readers can refer to [Arvind and Maessen, 2006]. [Guiady et al., 1999] looks at memory models from the point of view of performance. [Peterson et al., 1991] and [russell, 1978] describe two fully functional SIMD machines. For interconnection networks the reader can refer to [Jerger and Peh, 2009]. ",
        "page_idx": 635
    },
    {
        "type": "text",
        "text": "Exercises ",
        "text_level": 1,
        "page_idx": 635
    },
    {
        "type": "text",
        "text": "Overview of Multiprocessor Systems ",
        "text_level": 1,
        "page_idx": 635
    },
    {
        "type": "text",
        "text": "Ex. 1 \u2014 Differentiate between strongly coupled, and loosely coupled multiprocessors. ",
        "page_idx": 635
    },
    {
        "type": "text",
        "text": "Ex. 2 \u2014 Differentiate between shared memory, and message-passing-based multiprocessors. ",
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "Ex. 3 \u2014 Why is the evolution of multicore processors a direct consequence of Moore\u2019s Law? ",
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "Ex. 4 \u2014 The fraction of the potentially parallel section in a program is 0.6. What is the maximum speedup that we can achieve over a single core processor, if we run the program on a quad-core processor? ",
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "Ex. 5 \u2014 You need to run a program, 60% of which is strictly sequential, while the rest 40% can be fully parallelized over a maximum of 4 cores. You have 2 machines: ",
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "(a) A single core machine running at 3.2 GHz (b) A 4-core machine running at 2.4 GHz ",
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "Which machine is better if you have to minimize the total time taken to run the program? Assume that the two machines have the same IPC per thread and only differ in the clock frequency and the number of cores. ",
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "\\* Ex. 6 \u2014 Consider a program, which has a sequential and a parallel portion. The sequential portion is 40% and the parallel portion is $6 0 \\%$ . Using Amdahl\u2019s law, we can compute the speedup with $n$ processors, as $S ( n )$ . However, increasing the number of cores increases the cost of the entire system. Hence, we define a utility function, $g ( n )$ , of the form: ",
        "page_idx": 636
    },
    {
        "type": "equation",
        "text": "$$\ng ( n ) = e ^ { - n / 3 } ( 2 n ^ { 2 } + 7 n + 6 )\n$$",
        "text_format": "latex",
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "The buyer wishes to maximize $S ( n ) \\times g ( n )$ . What is the optimal number of processors, $n$ ? ",
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "Ex. 7 \u2014 Define the terms: SISD, SIMD, MISD, and MIMD. Give an example of each type of machine. ",
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "Ex. 8 \u2014 What are the two classes of MIMD machines introduced in this book? ",
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "Coherence and Consistency ",
        "text_level": 1,
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "Ex. 9 \u2014 What are the axioms of cache coherence? ",
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "Ex. 10 \u2014 Define sequential and weak consistency. ",
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "Ex. 11 \u2014 Is the outcome (t1,t2) = (2,1) allowed in a system with coherent memory? ",
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "Thread 1: ",
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "Thread 2: ",
        "page_idx": 636
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { r } { \\mathrm { ~  ~ x ~ } = \\mathrm { ~  ~ 1 ~ } ; } \\\\ { \\mathrm { ~  ~ x ~ } = \\mathrm { ~  ~ 2 ~ } ; } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 636
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { r } { \\mathbf { t } 1 \\ = \\ \\mathbf { x } ; } \\\\ { \\mathbf { t } 2 \\ = \\ \\mathbf { x } ; } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "Ex. 12 \u2014 Assume that all the global variables are initialized to 0, and all variables local to a thread start with \u2018t\u2019. What are the possible values of $t 1$ for a sequentially consistent system, and a weakly consistent system? (source [Adve and Gharachorloo, 1996]) ",
        "page_idx": 636
    },
    {
        "type": "text",
        "text": "Thread 1: ",
        "page_idx": 637
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { r } { \\mathrm { ~  ~ x ~ } = \\mathrm { ~  ~ 1 ~ } ; } \\\\ { \\mathrm { ~  ~ y ~ } = \\mathrm { ~  ~ 1 ~ } ; } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 637
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { l } { { \\mathrm { w h i l e \\left( y \\ = = \\ 0 \\right) \\left\\{ \\right\\} } } } \\\\ { { \\mathrm { t } 1 \\ = \\ \\mathrm { x } ; } } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 637
    },
    {
        "type": "text",
        "text": "Ex. 13 \u2014 Is the outcome $( \\mathrm { t } 1 , \\mathrm { t } 2 ) = ( 1 , 1 )$ possible in a sequentially consistent system? ",
        "page_idx": 637
    },
    {
        "type": "text",
        "text": "Thread 1: ",
        "page_idx": 637
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { l } { \\mathrm { {  ~ x ~ } = ~ 1 ; } } \\\\ { \\mathrm { { \\dot { \\ a f } \\left( y \\begin{array} { l } { \\mathrm { { = = } ~ 0 } } \\end{array} \\right) } } } \\\\ { \\mathrm { { \\dot { \\ t } 1 ~ } = ~ 1 ; } } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 637
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { l } { \\displaystyle \\textrm { y = 1 } ; } \\\\ { \\displaystyle \\dot { \\mathrm { \\scriptsize ~ i f ~ } } ( \\mathrm { x = = ~ } 0 ) } \\\\ { \\displaystyle \\qquad \\dot { \\mathrm { \\scriptsize ~ t } } 2 = \\mathrm { \\scriptsize ~ 1 } ; } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 637
    },
    {
        "type": "text",
        "text": "Ex. 14 \u2014 Is the outcome $t 1 \\neq t 2$ possible in a sequentially consistent system? (source [Adve and Gharachorloo, 1996]) ",
        "page_idx": 637
    },
    {
        "type": "text",
        "text": "Thread 3: Thread 4: Thread 1: Thread 2: ",
        "page_idx": 637
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 637
    },
    {
        "type": "text",
        "text": "z = 1; $\\begin{array} { l l } { { \\mathrm {  ~ z ~ } = ~ 2 ; ~ } } & { { ~ \\mathrm {  ~ { \\ w h i l e ~ } ~ ( { \\bf x } ~ \\mathrm {  ~ ! } = ~ 1 ) ~ } \\mathrm {  ~ \\left\\{ ~ \\right\\} ~ } } } \\\\ { { \\mathrm {  ~ y ~ } = ~ 1 ; ~ } } & { { ~ \\mathrm {  ~ { \\ w h i l e ~ } ~ } \\mathrm {  ~ { \\Lambda ~ } } ( { \\mathrm {  ~ y ~ } } \\mathrm {  ~ ! } = ~ 1 ) ~ \\mathrm {  ~ \\left\\{ ~ \\right\\} ~ } } } \\\\ { { ~ \\mathrm {  ~ { \\ t ~ } ~ } } } & { { ~ \\mathrm {  ~ { \\Lambda ~ } ~ } + \\mathrm {  ~ { \\Lambda ~ } ~ } \\mathrm {  ~ { \\Lambda ~ } ~ } } } \\end{array}$ $\\begin{array} { l } { { \\mathrm { w h i l e ~  { \\left( \\mathbf { x } \\{ \\theta \\right)} : = \\ { 1 }  } ~  { \\left\\{ \\begin{array} { l } { { } } } \\\\ { { \\mathrm { w h i l e ~  { \\left( \\mathbf { y } \\{ \\theta \\right)} : = \\ { 1 }  } ~  { \\left\\{ \\mathbf { \\xi } \\right\\} } } } \\end{ } } } }   \\\\ { \\right\\{ \\mathrm { t } 2 \\ = \\ \\mathbf { z } ; } } \\end{array} \\end{array}$   \n$\\textbf { x } = \\textbf { 1 } ;$ ; ",
        "page_idx": 637
    },
    {
        "type": "text",
        "text": "\\* Ex. 15 \u2014 Is the outcome $\\mathrm { t } 1 = 0$ ) allowed in a system with coherent memory and atomic writes? Consider both sequential and weak consistency? ",
        "page_idx": 637
    },
    {
        "type": "text",
        "text": "Thread 1: ",
        "page_idx": 637
    },
    {
        "type": "text",
        "text": "Thread 2: Thread 3: ",
        "page_idx": 637
    },
    {
        "type": "text",
        "text": "$\\textbf { x } = \\mathbf { \\nabla } _ { 1 } ;$ ",
        "page_idx": 637
    },
    {
        "type": "equation",
        "text": "$$\n\\begin{array} { l } { { \\mathrm { w h i l e ( x ~ \\mathrel {  {  } } = ~ \\mathrel {  {  { \\vphantom {  {  { \\operatorname { 1 } } } }  }  }  }  \\kern - delimiterspace }  \\} } } \\\\ { { \\mathrm { y ~ = ~ \\mathrel {  {  { \\vphantom {  { \\operatorname { 1 } } }  }  }  } } } } \\end{array}\n$$",
        "text_format": "latex",
        "page_idx": 637
    },
    {
        "type": "text",
        "text": "$^ * \\mathbf { E x }$ . 16 \u2014 Consider the following code snippet for implementing a critical section. A critical section is a region of code that can only be executed by one thread at any single point of time. Assume that we have two threads with ids 0 and 1, respectively. The function $g e t T i d ( )$ returns the id of the current thread. ",
        "page_idx": 637
    },
    {
        "type": "text",
        "text": "Is it possible for two threads to be in the critical section at the same point of time? ",
        "page_idx": 637
    },
    {
        "type": "text",
        "text": "Ex. 17 \u2014 In the snoopy protocol, why do we write back data to the main memory upon an $M$ to $S$ transition? ",
        "page_idx": 638
    },
    {
        "type": "text",
        "text": "Ex. 18 \u2014 Assume that two nodes desire to transition from the $S$ state to the $M$ state at exactly the same point of time. How will the snoopy protocol ensure that only one of these nodes enters the $M$ state, and finishes its write operation? What happens to the other node? ",
        "page_idx": 638
    },
    {
        "type": "text",
        "text": "Ex. 19 \u2014 The snoopy protocol clearly has an issue with scalability. If we have 64 cores with a private cache per core, then it will take a long time to broadcast a message to all the caches. Can you propose solutions to circumvent this problem? ",
        "page_idx": 638
    },
    {
        "type": "text",
        "text": "Ex. 20 \u2014 Let us assume a cache coherent multiprocessor system. The L1 cache is private and the coherent L2 cache is shared across the processors. Let us assume that the system issues a lot of I/O requests. Most of the I/O requests perform DMA (Direct Memory Access) from main memory. It is possible that the I/O requests might overwrite some data that is already present in the caches. In this case we need to extend the cache coherence protocol that also takes I/O accesses into account. Propose one such protocol. ",
        "page_idx": 638
    },
    {
        "type": "text",
        "text": "Ex. 21 \u2014 Let us define a new state in the traditional $M S I$ states-based snoopy protocol. The new $E$ state refers to the \u201cexclusive\u201d state, in which a processor is sure that no other cache contains the block in a valid state. Secondly, in the $E$ state, the processor hasn\u2019t modified the block yet. What is the advantage of having the $E$ state? How are evictions handled in the $E$ state? ",
        "page_idx": 638
    },
    {
        "type": "text",
        "text": "Ex. 22 \u2014 Show the state transition diagrams for an MSI protocol with a directory. You need to show the following: ",
        "page_idx": 638
    },
    {
        "type": "text",
        "text": "1.Structure of the directory   \n2.State transition diagram for events received from the host processor.   \n3.State transition diagram for events received from the directory.   \n4.State transition diagram for an entry in the directory (if required). ",
        "page_idx": 638
    },
    {
        "type": "text",
        "text": "Ex. 23 \u2014 Assume that we have a system with private L1 and L2 caches. The L1 layer is not coherent. However, the L2 layer maintains cache coherence. How do we modify our $M S I$ snoopy protocol to support cache coherence for the entire system? ",
        "page_idx": 638
    },
    {
        "type": "text",
        "text": "Ex. 24 \u2014 In the snoopy write-invalidate protocol, when should a processor actually perform the write operation? Should it perform the write as soon as possible, or should it wait for the write-invalidate message to reach all the caches? Explain your answer. ",
        "page_idx": 638
    },
    {
        "type": "text",
        "text": "\\* Ex. 25 \u2014 Assume that a processor wants to perform an atomic exchange operation between two memory locations $a$ and $b$ . $a$ and $b$ cannot be allocated to registers. How will you modify the $M S I$ coherence protocol to support this operation? Before proceeding with the answer think about what are the things that can go wrong. An exchange is essentially equivalent to the following sequence of operations: (1) temp = a; (2) a = b; (3) b = temp. If a read arrives between operations (2) and (3) it might get the wrong value of b. We need to prevent this situation. ",
        "page_idx": 638
    },
    {
        "type": "text",
        "text": "\\*\\* Ex. 26 \u2014 Assume that we want to implement an instruction called $M C A S$ . The $M C A S$ instruction takes $k$ (known and bounded) memory locations as arguments, a set of $k$ old values, and a set of $k$ new values. Its pseudo-code is shown below. We assume here that mem is a hypothetical array representing the entire memory space. ",
        "page_idx": 639
    },
    {
        "type": "text",
        "text": "$^ { \\prime * }$ multiple compare and set \\*/   \nboolean MCAS(int memLocs[], int oldValues[], int newValues[]){ /\\* compare \\*/ for( $\\scriptstyle { \\dot { \\mathsf { I } } } = 0$ ; i < k; i++) { if(mem[memLocs[i]] ! $\\smash { \\ ! = }$ oldValues[i]) { return false; } } /\\* set \\*/ for( $\\scriptstyle { \\dot { \\mathsf { 1 } } } = 0$ ; i < k; i++) { mem[memLocs[i]] $\\mathbf { \\sigma } = \\mathbf { \\sigma }$ newValues[i]; } return true;   \n} ",
        "page_idx": 639
    },
    {
        "type": "text",
        "text": "The challenge is to implement this instruction such that it appears to execute instantaneously. Let us look at some subtle cases. Assume that we want to write (4,5,6) to three memory locations if their previous contents are (1,2,3). It is possible that after writing 4, and 5, there is a small delay. During this time another thread reads the three memory locations, and concludes that their values are 4,5, and 3, respectively. This result is incorrect because it violates our assumption that $M C A S$ executes instantaneously. We should either read (1,2,3) or (4,5,6). ",
        "page_idx": 639
    },
    {
        "type": "text",
        "text": "Now, let us look at the case of reading the three memory locations. Let us say that their initial values are 1,2, and 0. Our $M C A S$ instruction reads the first two locations and since they are equal to the old values, proceeds to the third location. Before reading it, a store operation from another thread changes the values of the three locations as follows. $( 1 , 2 , 0 )  ( 5 , 2 , 0 )  ( 5 , 2 , 3 )$ . Subsequently, the $M C A S$ instruction takes a look at the third memory location and finds it to be 3. Note that the three memory locations were never equal to (1,2,3). We thus arrive at a wrong conclusion. ",
        "page_idx": 639
    },
    {
        "type": "text",
        "text": "How should we fix these problems? We want to implement an $M C A S$ instruction purely in hardware, which provides an illusion of instantaneous execution. It should be free of deadlocks, and should complete in a finite amount of time. How can we extend our coherence protocols to implement it? ",
        "page_idx": 639
    },
    {
        "type": "text",
        "text": "\\*\\*\\* Ex. 27 \u2014 Assume a processor that has a sequentially consistent(SC) memory. We implement SC by making each thread wait for a memory request to complete before issuing the next request. Now, assume that we modify the architecture by allowing a processor to read a value that the immediately preceding instruction has written without waiting for it to complete. Prove that the memory system still follows SC. ",
        "page_idx": 639
    },
    {
        "type": "text",
        "text": "\\*\\*\\* Ex. 28 \u2014 Assume a processor with a weak consistency model. Let us run a \u201cproperly labeled\u201d program on it. A properly labeled(PL) program does not allow conflicting accesses (read-write, write-read, or write-write) to a shared variable at the same time. For example, the following code sequence is not properly labeled because it allows $x$ to be modified concurrently. ",
        "page_idx": 639
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "Thread 1: ",
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "Thread 2: ",
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "$\\mathrm { ~ \\tt ~ x ~ } = \\mathrm { ~ 0 ~ }$ $\\texttt { x } = \\texttt { 1 }$ In reality, the coherence protocol orders one write access before the other. Nevertheless, both the threads try to modify $x$ concurrently at the programmer\u2019s level. This is precisely the behavior that we wish to avoid. ",
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "In a PL program, two threads do not try to modify $x$ at the same time. This is achieved by having two magic instructions known as lock and unlock. Only one thread can lock a memory location at any point of time. If another thread tries to lock the location before it is unlocked, then it stalls till the lock is free. If multiple threads are waiting on the same lock, only one of them is given the lock after a unlock instruction. Secondly, both the lock and unlock instructions have a built-in fence operation, and all the lock and unlock instructions execute in program order. The PL version of our program is as follows: ",
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "Thread 1: ",
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "Thread 2: ",
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "lock(x) $\\texttt { x } = \\texttt { 0 }$ unlock(x) ",
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "We can thus think of a lock-unlock block as a sequential block that can only be executed by one thread at a given time. Moreover, assume that a lock-unlock block can only have one memory instruction inside it. ",
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "Now, prove that all PL programs running on a weakly consistent machine have a sequentially consistent execution. In other words we can interleave the memory accesses of all the threads such that they appear to be executed by a single cycle processor that switches among the threads. [HINT: Construct access graphs for your system, and prove that they are acyclic.] ",
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "Multithreading ",
        "text_level": 1,
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "Ex. 29 \u2014 What is the difference between a fine grained and coarse grained multithreaded machine? ",
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "Ex. 30 \u2014 Describe a simultaneous multithreaded (SMT) processor in detail. ",
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "Ex. 31 \u2014 Describes the steps that we need to take to ensure that an SMT processor executes correctly. ",
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "Ex. 32 \u2014 Assume a mix of workloads in a 4-way SMT processor. 2 threads are computationally intensive, 1 thread is I/O intensive, and the last thread sleeps for a long time. Design an efficient instruction selection scheme. ",
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "Interconnection Networks ",
        "text_level": 1,
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "Ex. 33 \u2014 What is the bisection bandwidth and diameter of a 2D $n \\times n$ mesh? ",
        "page_idx": 640
    },
    {
        "type": "text",
        "text": "Ex. 34 \u2014 What is the bisection bandwidth and diameter of a 3D $n \\times n \\times n$ mesh? ",
        "page_idx": 641
    },
    {
        "type": "text",
        "text": "Ex. 35 \u2014 What is the diameter of a ring containing $n$ nodes? Give a precise answer that holds for even and odd $n$ . ",
        "page_idx": 641
    },
    {
        "type": "text",
        "text": "Ex. 36 \u2014 What is the bisection bandwidth and diameter of a hypercube of order $n$ . ",
        "page_idx": 641
    },
    {
        "type": "text",
        "text": "Ex. 37 \u2014 What is the bisection bandwidth and diameter of an $n \\times n \\times n$ , 3D torus? ",
        "page_idx": 641
    },
    {
        "type": "text",
        "text": "Ex. 38 \u2014 What is the bisection bandwidth and diameter of a clique of $n$ nodes ( $n$ is even)? In a clique, all pairs of nodes are connected. ",
        "page_idx": 641
    },
    {
        "type": "text",
        "text": "$^ { * * }$ Ex. 39 \u2014 Assume we have an $n \\times n$ mesh. There are $n ^ { 2 }$ routers, and each processor is connected to one router. Note that at any point of time, a router can only store 1 message. It will discard a message only if the message gets stored in another router. In our previous example, router $( i , j )$ will keep the message until it has been delivered and stored at a neighboring router such as $( i + 1 , j )$ . Now, an interesting deadlock situation can develop. Let us assume the following scenario. ",
        "page_idx": 641
    },
    {
        "type": "text",
        "text": "\u2022(1,1) wants to send a message to (1,2).   \n\u2022(1,2) wants to send a message to (2,2).   \n$\\bullet$ (2,2) wants to send a message to (2,1).   \n$\\bullet$ (2,1) wants to send a message to (1,1). ",
        "page_idx": 641
    },
    {
        "type": "text",
        "text": "In this case all the four nodes have 1 message each. They are not able to forward the packet to the next node, because the next node already stores a packet, and is thus busy. Since there is a cyclic wait, we have a deadlock. Design a message routing protocol between a source and destination node that is provably deadlock free. ",
        "page_idx": 641
    },
    {
        "type": "text",
        "text": "Vector Processors ",
        "text_level": 1,
        "page_idx": 641
    },
    {
        "type": "text",
        "text": "Ex. 40 \u2014 What is the advantage of vector processors over scalar processors? ",
        "page_idx": 641
    },
    {
        "type": "text",
        "text": "Ex. 41 \u2014 Why are vector load-store instructions easy to implement in systems that have caches with large block sizes? ",
        "page_idx": 641
    },
    {
        "type": "text",
        "text": "Ex. 42 \u2014 How can we efficiently implement a scatter-gather-based load-store unit? ",
        "page_idx": 641
    },
    {
        "type": "text",
        "text": "Ex. 43 \u2014 What is a predicated instruction, and how does it help speed up a vector processor? ",
        "page_idx": 641
    },
    {
        "type": "text",
        "text": "\\* Ex. 44 \u2014 Assume that we have a processor with a 32 entry vector register file. We wish to add two arrays that have 17 entries each. How can we implement this operation, with the SimpleRisc vector instructions introduced in the chapter? Feel free to introduce new vector instructions if required. ",
        "page_idx": 641
    },
    {
        "type": "text",
        "text": "\\* Ex. 45 \u2014 Design a dedicated SIMD hardware unit to sort $n$ integers in roughly $n$ time steps by using the bubble sort algorithm. You have a linear array of $n$ processors connected end to end. Each processor is capable of storing two integers, and has some logic inside it. Design the logic for each processor and explain the overall working of the system. ",
        "page_idx": 641
    },
    {
        "type": "text",
        "text": "Design Problems ",
        "text_level": 1,
        "page_idx": 642
    },
    {
        "type": "text",
        "text": "Ex. 46 \u2014 Write a program to sort a billion integers using OpenMP and MPI. Ex. 47 \u2014 Implement a distributed shared memory system on a cluster of computers connected via an Ethernet LAN. ",
        "page_idx": 642
    }
]