[
    {
        "type": "text",
        "text": "29.5 Summary ",
        "text_level": 1,
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "We have introduced a sampling of concurrent data structures, from counters, to lists and queues, and finally to the ubiquitous and heavilyused hash table. We have learned a few important lessons along the way: to be careful with acquisition and release of locks around control flow ",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "OPERATINGSYSTEMS[VERSION 1.10]",
        "page_idx": 11
    },
    {
        "type": "image",
        "img_path": "images/b5497beaca675383c84d6d1832e498e1416ca681488e50166cc9076b749e7cd6.jpg",
        "img_caption": [
            "Figure 29.11: Scaling Hash Tables "
        ],
        "img_footnote": [],
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "changes; that enabling more concurrency does not necessarily increase performance; that performance problems should only be remedied once they exist. This last point, of avoiding premature optimization, is central to any performance-minded developer; there is no value in making something faster if doing so will not improve the overall performance of the application. ",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "Of course, we have just scratched the surface of high performance structures. See Moir and Shavit’s excellent survey for more information, as well as links to other sources [MS04]. In particular, you might be interested in other structures (such as B-trees); for this knowledge, a database class is your best bet. You also might be curious about techniques that don’t use traditional locks at all; such non-blocking data structures are something we’ll get a taste of in the chapter on common concurrency bugs, but frankly this topic is an entire area of knowledge requiring more study than is possible in this humble book. Find out more on your own if you desire (as always!). ",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "TIP: AVOID PREMATURE OPTIMIZATION (KNUTH’S LAW) When building a concurrent data structure, start with the most basic approach, which is to add a single big lock to provide synchronized access. By doing so, you are likely to build a correct lock; if you then find that it suffers from performance problems, you can refine it, thus only making it fast if need be. As Knuth famously stated, “Premature optimization is the root of all evil.” ",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "Many operating systems utilized a single lock when first transitioning to multiprocessors, including Sun OS and Linux. In the latter, this lock even had a name, the big kernel lock (BKL). For many years, this simple approach was a good one, but when multi-CPU systems became the norm, only allowing a single active thread in the kernel at a time became a performance bottleneck. Thus, it was finally time to add the optimization of improved concurrency to these systems. Within Linux, the more straightforward approach was taken: replace one lock with many. Within Sun, a more radical decision was made: build a brand new operating system, known as Solaris, that incorporates concurrency more fundamentally from day one. Read the Linux and Solaris kernel books for more information about these fascinating systems [BC05, MM00]. ",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "OPERATINGSYSTEMS[VERSION 1.10]",
        "page_idx": 13
    }
]