[
    {
        "type": "text",
        "text": "54.6 Authentication by What You Are ",
        "text_level": 1,
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "If you don’t like methods like passwords and you don’t like having to hand out smart cards or security tokens to your users, there is another option. Human beings (who are what we’re talking about authenticating here) are unique creatures with physical characteristics that differ from all others, sometimes in subtle ways, sometimes in obvious ones. In addition to properties of the human body (from DNA at the base up to the appearance of our face at the top), there are characteristics of human behavior that are unique, or at least not shared by very many others. This observation suggests that if our operating system can only accurately measure these properties or characteristics, it can distinguish one person from another, solving our authentication problem. ",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "This approach is very attractive to many people, most especially to those who have never tried to make it work. Going from the basic observation to a working, reliable authentication system is far from easy. But it can be made to work, to much the same extent as the other authentication mechanisms. We can use it, but it won’t be perfect, and has its own set of problems and challenges. ",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "Remember that we’re talking about a computer program (either the OS itself or some separate program it invokes for the purpose) measuring a human characteristic and determining if it belongs to a particular person. Think about what that entails. What if we plan to use facial recognition with the camera on a smart phone to authenticate the owner of the phone? If we decide it’s the right person, we allow whoever we took the picture of to use the phone. If not, we give them the raspberry (in the cyber sense) and keep them out. ",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "You should have identified a few challenges here. First, the camera is going to take a picture of someone who is, presumably, holding the phone. Maybe it’s the owner, maybe it isn’t. That’s the point of taking the picture. If it isn’t, we should assume whoever it is would like to fool us into thinking that they are the actual owner. What if it’s someone who looks a lot like the right user, but isn’t? What if the person is wearing a mask? What if the person holds up a photo of the right user, instead of their own face? What if the lighting is dim, or the person isn’t fully facing the camera? Alternately, what if it is the right user and the person is not facing the camera, or the lighting is dim, or something else has changed about the person’s look? (e.g., hairstyle) ",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "Computer programs don’t recognize faces the way people do. They do what programs always do with data: they convert it to zeros and ones and process it using some algorithm. So that “photo” you took is actually a collection of numbers, indicating shadow and light, shades of color, contrasts, and the like. OK, now what? Time to decide if it’s the right person’s photo or not! How? ",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "If it were a password, we could have stored the right password (or, better, a hash of the right password) and done a comparison of what got typed in (or its hash) to what we stored. If it’s a perfect match, authenticate. Otherwise, don’t. Can we do the same with this collection of zeros and ones that represent the picture we just took? Can we have a picture of the right user stored permanently in some file (also in the form of zeros and ones) and compare the data from the camera to that file? ",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "Probably not in the same way we compared the passwords. Consider one of those factors we just mentioned above: lighting. If the picture we stored in the file was taken under bright lights and the picture coming out of the camera was taken under dim lights, the two sets of zeros and ones are most certainly not going to match. In fact, it’s quite unlikely that two pictures of the same person, taken a second apart under identical conditions, would be represented by exactly the same set of bits. So clearly we can’t do a comparison based on bit-for-bit equivalence. ",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "Instead, we need to compare based on a higher-level analysis of the two photos, the stored one of the right user and the just-taken one of the person who claims to be that user. Generally this will involve extracting higher-level features from the photos and comparing those. We might, for example, try to calculate the length of the nose, or determine the color of the eyes, or make some kind of model of the shape of the mouth. Then we would compare the same feature set from the two photos. ",
        "page_idx": 12
    },
    {
        "type": "image",
        "img_path": "images/42fe9829e697e1877714853affb83410049bdecc90ada0e3b2ba0eb4583b64fa.jpg",
        "img_caption": [
            "Figure 54.1: Crossover Error Rate "
        ],
        "img_footnote": [],
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "Even here, though, an exact match is not too likely. The lighting, for example, might slightly alter the perceived eye color. So we’ll need to allow some sloppiness in our comparison. If the feature match is “close enough,” we authenticate. If not, we don’t. We will look for close matches, not perfect matches, which brings the nose of the camel of tolerances into our authentication tent. If we are intolerant of all but the closest matches, on some days we will fail to match the real user’s picture to the stored version. That’s called a false negative, since we incorrectly decided not to authenticate. If we are too tolerant of differences in measured versus stored data, we will authenticate a user whom is not who they claim to be. That’s a false positive, since we incorrectly decided to authenticate. ",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "The nature of biometrics is that any implementation will have a characteristic false positive and false negative rate. Both are bad, so you’d like both to be low. For any given implementation of some biometric authentication technique, you can typically tune it to achieve some false positive rate, or tune it to achieve some false negative rate. But you usually can’t minimize both. As the false positive rate goes down, the false negative rate goes up, and vice versa. The sensitivity describes how close the match must be. ",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "Figure 54.1 shows the typical relationship between these error rates. Note the circle at the point where the two curves cross. That point represents the crossover error rate, a common metric for describing the accuracy of a biometric. It represents an equal tradeoff between the two kinds of errors. It’s not always the case that one tunes a biometric system to hit the crossover error rate, since you might care more about one kind of error than the other. For example, a smart phone that frequently locks its legitimate user out because it doesn’t like today’s fingerprint reading is not going to be popular, while the chances of a thief who stole the phone having a similar fingerprint are low. Perhaps low false negatives matter ",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "OPERATINGSYSTEMS[VERSION 1.10]",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "more here. On the other hand, if you’re opening a bank vault with a retinal scan, requiring the bank manager to occasionally provide a second scan isn’t too bad, while allowing a robber to open the vault with a bogus fake eye would be a disaster. Low false positives might be better here. ",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "Leaving aside the issues of reliability of authentication using biometrics, another big issue for using human characteristics to authenticate is that many of the techniques for measuring them require special hardware not likely to be present on most machines. Many computers (including smart phones, tablets, and laptops) are likely to have cameras, but embedded devices and server machines probably don’t. Relatively few machines have fingerprint readers, and even fewer are able to measure more exotic biometrics. While a few biometric techniques (such as measuring typing patterns) require relatively common hardware that is likely to be present on many machines anyway, there aren’t many such techniques. Even if a special hardware device is available, the convenience of using them for this purpose can be limiting. ",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "One further issue you want to think about when considering using biometric authentication is whether there is any physical gap between where the biometric quantity is measured and where it is checked. In particular, checking biometric readings provided by an untrusted machine across the network is hazardous. What comes in across the network is simply a pattern of bits spread across one or more messages, whether it represents a piece of a web page, a phoneme in a VoIP conversation, or part of a scanned fingerprint. Bits are bits, and anyone can create any bit pattern they want. If a remote adversary knows what the bit pattern representing your fingerprint looks like, they may not need your finger, or even a fingerprint scanner, to create it and feed it to your machine. When the hardware performing the scanning is physically attached to your machine, there is less opportunity to slip in a spurious bit pattern that didn’t come from the device. When the hardware is on the other side of the world on a machine you have no control over, there is a lot more opportunity. The point here is to be careful with biometric authentication information provided to you remotely. ",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "In all, it sort of sounds like biometrics are pretty terrible for authentication, but that’s the wrong lesson. For that matter, previous sections probably made it sound like all methods of authentication are terrible. Certainly none of them are perfect, but your task as a system designer is not to find the perfect authentication mechanism, but to use mechanisms that are well suited to your system and its environment. A good fingerprint reader built in to a smart phone might do its job quite well. A long, unguessable password can provide a decent amount of security. Well-designed smart cards can make it nearly impossible to authenticate yourself without having them in your hand. And where each type of mechanism fails, you can perhaps correct for that failure by using a second or third authentication mechanism that doesn’t fail in the same cases. ",
        "page_idx": 14
    }
]