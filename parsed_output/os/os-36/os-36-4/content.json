[
    {
        "type": "text",
        "text": "36.4 Lowering CPU Overhead With Interrupts ",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "The invention that many engineers came upon years ago to improve this interaction is something we’ve seen already: the interrupt. Instead of polling the device repeatedly, the OS can issue a request, put the calling process to sleep, and context switch to another task. When the device is finally finished with the operation, it will raise a hardware interrupt, causing the CPU to jump into the OS at a predetermined interrupt service routine (ISR) or more simply an interrupt handler. The handler is just a piece of operating system code that will finish the request (for example, by reading data and perhaps an error code from the device) and wake the process waiting for the $1 / { \\dot { \\mathrm { O } } } ,$ , which can then proceed as desired. ",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "Interrupts thus allow for overlap of computation and $\\mathrm { I } / \\mathrm { O } ,$ which is key for improved utilization. This timeline shows the problem: ",
        "page_idx": 4
    },
    {
        "type": "table",
        "img_path": "images/711d36b0e58467bb1e6cb0e09fcef91d39cb8eeb3a25a432b4ce158470b4497b.jpg",
        "table_caption": [],
        "table_footnote": [],
        "table_body": "\n\n<html><body><table><tr><td>CPU</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>p</td><td>p</td><td>p</td><td>p</td><td>p</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr><tr><td>Disk</td><td></td><td></td><td></td><td></td><td></td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td></td><td></td><td></td><td></td></tr></table></body></html>\n\n",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "In the diagram, Process 1 runs on the CPU for some time (indicated by a repeated 1 on the CPU line), and then issues an $\\mathrm { I } / \\mathrm { O }$ request to the disk to read some data. Without interrupts, the system simply spins, polling the status of the device repeatedly until the $\\mathrm { I } \\dot { / } \\mathrm { O }$ is complete (indicated by a p). The disk services the request and finally Process 1 can run again. ",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "If instead we utilize interrupts and allow for overlap, the OS can do something else while waiting for the disk: ",
        "page_idx": 4
    },
    {
        "type": "image",
        "img_path": "images/9731532c62d01f39045c533833ea2a2665ba19d00003eccc4a149e3056505c2e.jpg",
        "img_caption": [],
        "img_footnote": [],
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "In this example, the OS runs Process 2 on the CPU while the disk services Process 1’s request. When the disk request is finished, an interrupt occurs, and the OS wakes up Process 1 and runs it again. Thus, both the CPU and the disk are properly utilized during the middle stretch of time. ",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "Note that using interrupts is not always the best solution. For example, imagine a device that performs its tasks very quickly: the first poll usually finds the device to be done with task. Using an interrupt in this case will actually slow down the system: switching to another process, handling the interrupt, and switching back to the issuing process is expensive. Thus, if a device is fast, it may be best to poll; if it is slow, interrupts, which allow ",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "TIP: INTERRUPTS NOT ALWAYS BETTER THAN POLLING Although interrupts allow for overlap of computation and I/O, they only really make sense for slow devices. Otherwise, the cost of interrupt handling and context switching may outweigh the benefits interrupts provide. There are also cases where a flood of interrupts may overload a system and lead it to livelock [MR96]; in such cases, polling provides more control to the OS in its scheduling and thus is again useful. ",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "overlap, are best. If the speed of the device is not known, or sometimes fast and sometimes slow, it may be best to use a hybrid that polls for a little while and then, if the device is not yet finished, uses interrupts. This two-phased approach may achieve the best of both worlds. ",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "Another reason not to use interrupts arises in networks [MR96]. When a huge stream of incoming packets each generate an interrupt, it is possible for the OS to livelock, that is, find itself only processing interrupts and never allowing a user-level process to run and actually service the requests. For example, imagine a web server that experiences a load burst because it became the top-ranked entry on hacker news [H18]. In this case, it is better to occasionally use polling to better control what is happening in the system and allow the web server to service some requests before going back to the device to check for more packet arrivals. ",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "Another interrupt-based optimization is coalescing. In such a setup, a device which needs to raise an interrupt first waits for a bit before delivering the interrupt to the CPU. While waiting, other requests may soon complete, and thus multiple interrupts can be coalesced into a single interrupt delivery, thus lowering the overhead of interrupt processing. Of course, waiting too long will increase the latency of a request, a common trade-off in systems. See Ahmad et al. $\\left[ { \\mathsf { A } } { + } 1 1 \\right]$ for an excellent summary. ",
        "page_idx": 5
    }
]