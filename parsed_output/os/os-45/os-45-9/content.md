# 45.9 Summary  

We have discussed data protection in modern storage systems, focusing on checksum implementation and usage. Different checksums protect against different types of faults; as storage devices evolve, new failure modes will undoubtedly arise. Perhaps such change will force the research community and industry to revisit some of these basic approaches, or invent entirely new approaches altogether. Time will tell. Or it won’t. Time is funny that way.  

References   
$[ \mathsf { B } { + } 0 7 ]$ “An Analysis of Latent Sector Errors in Disk Drives” by L. Bairavasundaram, G. Goodson, S. Pasupathy, J. Schindler. SIGMETRICS $' 0 7$ , San Diego, CA. The first paper to study latent sector errors in detail. The paper also won the Kenneth C. Sevcik Outstanding Student Paper award, named after a brilliant researcher and wonderful guy who passed away too soon. To show the OSTEP authors it was possible to move from the U.S. to Canada, Ken once sang us the Canadian national anthem, standing up in the middle of a restaurant to do so. We chose the U.S., but got this memory. $\left[ { \tt B } { + } 0 8 \right]$ “An Analysis of Data Corruption in the Storage Stack” by Lakshmi N. Bairavasundaram, Garth R. Goodson, Bianca Schroeder, Andrea C. Arpaci-Dusseau, Remzi H. ArpaciDusseau. FAST $^ { \prime } 0 8$ , San Jose, CA, February 2008. The first paper to truly study disk corruption in great detail, focusing on how often such corruption occurs over three years for over 1.5 million drives. [BS04] “Commercial Fault Tolerance: A Tale of Two Systems” by Wendy Bartlett, Lisa Spainhower. IEEE Transactions on Dependable and Secure Computing, Vol. 1:1, January 2004. This classic in building fault tolerant systems is an excellent overview of the state of the art from both IBM and Tandem. Another must read for those interested in the area.   
$\scriptstyle { [ C + 0 4 ] }$ “Row-Diagonal Parity for Double Disk Failure Correction” by P. Corbett, B. English, A. Goel, T. Grcanac, S. Kleiman, J. Leong, S. Sankar. FAST $' 0 4$ , San Jose, CA, February 2004. An early paper on how extra redundancy helps to solve the combined full-disk-failure/partial-disk-failure problem. Also a nice example of how to mix more theoretical work with practical.   
[F04] “Checksums and Error Control” by Peter M. Fenwick. Copy available online here: http://www.ostep.org/Citations/checksums-03.pdf. A great simple tutorial on checksums, available to you for the amazing cost of free.   
[F82] “An Arithmetic Checksum for Serial Transmissions” by John G. Fletcher. IEEE Transactions on Communication, Vol. 30:1, January 1982. Fletcher’s original work on his eponymous checksum. He didn’t call it the Fletcher checksum, rather he just didn’t call it anything; later, others named it after him. So don’t blame old Fletch for this seeming act of braggadocio. This anecdote might remind you of Rubik; Rubik never called it “Rubik’s cube”; rather, he just called it “my cube.”   
[HLM94] “File System Design for an NFS File Server Appliance” by Dave Hitz, James Lau, Michael Malcolm. USENIX Spring ’94. The pioneering paper that describes the ideas and product at the heart of NetApp’s core. Based on this system, NetApp has grown into a multi-billion dollar storage company. To learn more about NetApp, read Hitz’s autobiography “How to Castrate a Bull” (which is the actual title, no joking). And you thought you could avoid bull castration by going into CS.   
[K+08] “Parity Lost and Parity Regained” by Andrew Krioukov, Lakshmi N. Bairavasundaram, Garth R. Goodson, Kiran Srinivasan, Randy Thelen, Andrea C. Arpaci-Dusseau, Remzi H. Arpaci-Dusseau. FAST $^ { \prime } 0 8 .$ , San Jose, CA, February 2008. This work explores how different checksum schemes work (or don’t work) in protecting data. We reveal a number of interesting flaws in current protection strategies.   
[M13] “Cyclic Redundancy Checks” by unknown. Available: http://www.mathpages.com/ home/kmath458.htm. A super clear and concise description of CRCs. The internet is full of information, as it turns out.   
$\scriptstyle { [ { \mathrm { P } } + 0 5 ] }$ “IRON File Systems” by V. Prabhakaran, L. Bairavasundaram, N. Agrawal, H. Gunawi, A. Arpaci-Dusseau, R. Arpaci-Dusseau. SOSP ’05, Brighton, England. Our paper on how disks have partial failure modes, and a detailed study of how modern file systems react to such failures. As it turns out, rather poorly! We found numerous bugs, design flaws, and other oddities in this work. Some of this has fed back into the Linux community, thus improving file system reliability. You’re welcome! [RO91] “Design and Implementation of the Log-structured File System” by Mendel Rosenblum and John Ousterhout. SOSP ’91, Pacific Grove, CA, October 1991. So cool we cite it again. [S90] “Implementing Fault-Tolerant Services Using The State Machine Approach: A Tutorial” by Fred B. Schneider. ACM Surveys, Vol. 22, No. 4, December 1990. How to build fault tolerant services. A must read for those building distributed systems.   
$\left[ Z \mathrm { + } 1 3 \right]$ “Zettabyte Reliability with Flexible End-to-end Data Integrity” by Y. Zhang, D. Myers, A. Arpaci-Dusseau, R. Arpaci-Dusseau. MSST ’13, Long Beach, California, May 2013. How to add data protection to the page cache of a system. Out of space, otherwise we would write something...  

OPERATINGSYSTEMS[VERSION 1.10]  

# Homework (Simulation)  

In this homework, you’ll use checksum.py to investigate various aspects of checksums.  

# Questions  

1. First just run checksum.py with no arguments. Compute the additive, XOR-based, and Fletcher checksums. Use $- \mathtt { C }$ to check your answers.   
2. Now do the same, but vary the seed $( - s )$ to different values.   
3. Sometimes the additive and XOR-based checksums produce the same checksum (e.g., if the data value is all zeroes). Can you pass in a 4-byte data value (using the $- \mathtt { D }$ flag, e.g., $\mathrm { ~ - D ~ } \ a , \mathrm { b , c , d } )$ that does not contain only zeroes and leads the additive and XOR-based checksum having the same value? In general, when does this occur? Check that you are correct with the $- \mathtt { C }$ flag.   
4. Now pass in a 4-byte value that you know will produce a different checksum values for additive and XOR. In general, when does this occur?   
5. Use the simulator to compute checksums twice (once each for a different set of numbers). The two number strings should be different (e.g., $- \mathrm { { D } ^ { \Delta } \ a } \mathrm { { 1 , b } \mathrm { { 1 , c } \mathrm { { 1 , d } \mathrm { { 1 } } } } }$ the first time and $- { \bar { \mathrm { D } } } { \mathrm { ~ } } { \mathrm { a } } 2 , { \mathrm { b } } 2 , { \mathrm { c } } 2 , { \mathrm { d } } 2$ the second) but should produce the same additive checksum. In general, when will the additive checksum be the same, even though the data values are different? Check your specific answer with the $- \mathtt { C }$ flag.   
6. Now do the same for the XOR checksum.   
7. Now let’s look at a specific set of data values. The first is: $- \mathtt { D }$ 1,2,3,4. What will the different checksums (additive, XOR, Fletche be for this data? Now compare it to computing these checksums over $- \mathrm { D } \ \mathrm { ~ 4 ~ } , 3 , 2 , 1$ . What do you notice about these three checksums? How does Fletcher compare to the other two? How is Fletcher generally “better” than something like the simple additive checksum?   
8. No checksum is perfect. Given a particular input of your choosing, can you find other data values that lead to the same Fletcher checksum? When, in general, does this occur? Start with a simple data string (e.g., $\mathbf { - D } \bar { 0 } , 1 , 2 , 3 )$ and see if you can replace one of those numbers but end up with the same Fletcher checksum. As always, use $- \mathtt { C }$ to check your answers.  

# Homework (Code)  

In this part of the homework, you’ll write some of your own code to implement various checksums.  

# Questions  

1. Write a short C program (called check-xor.c) that computes an XOR-based checksum over an input file, and prints the checksum as output. Use a 8-bit unsigned char to store the (one byte) checksum. Make some test files to see if it works as expected.   
2. Now write a short C program (called check-fletcher.c) that computes the Fletcher checksum over an input file. Once again, test your program to see if it works.   
3. Now compare the performance of both: is one faster than the other? How does performance change as the size of the input file changes? Use internal calls to gettimeofday to time the programs. Which should you use if you care about performance? About checking ability?   
4. Read about the 16-bit CRC and then implement it. Test it on a number of different inputs to ensure that it works. How is its performance as compared to the simple XOR and Fletcher? How about its checking ability?   
5. Now build a tool (create-csum.c) that computes a single-byte checksum for every 4KB block of a file, and records the results in an output file (specified on the command line). Build a related tool (check-csum.c) that reads a file, computes the checksums over each block, and compares the results to the stored checksums stored in another file. If there is a problem, the program should print that the file has been corrupted. Test the program by manually corrupting the file.  