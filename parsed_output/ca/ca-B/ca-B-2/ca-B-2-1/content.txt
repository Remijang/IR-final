B.2.1 Work Distribution

Three kinds of work can be assigned to the GPU â€“ vertex processing, pixel processing, and regular computing jobs. The GPU defines its own assembly code, which uses the PTX and SASS instruction sets. Each instruction in these instruction sets defines a basic operation on the GPU. It uses either register operands, or memory operands. Unlike CPUs the structure of the register file in a GPU is typically not exposed to software. The programmer is expected to use an unlimited number of virtual registers. The GPU or the device driver map them to real registers.

Now, for processing vertices, low level graphics software sends a sequence of assembly instructions to the GPU. The GPU has a hardware assembler that produces binary code, and sends it to a dedicated vertex processing unit that co-ordinates and distributes the work among the cores in the GPU. Alternatively, the CPU can send pixel processing operations to the GPU. The GPU does the process of rasterization, fragment processing, and depth buffering. A dedicated unit in the GPU generates code snippets for these operations, and sends them to a pixel processing unit that distributes the work items among the set of GPU cores. The third unit is a compute work distributor that accepts regular computational tasks from the CPU such as adding two matrices, or computing a dot product of two vectors. The programmer specifies a set of subtasks. The role of the compute work distribution engine is to send these set of subtasks to cores in the GPU.

Beyond this stage, the GPU is more or less oblivious of the source of the instructions. Note that this piece of engineering is the key contribution behind making GPUs successful. Designers have successfully split the functionality of a GPU into two layers. The first layer is specific to the type of operation (graphics or general purpose). The role of each pipeline in this stage is to transform the specific sequence of operations into a generic set of actions such that irrespective of the nature of the high level operation, the same set of hardware units can be used. Let us now take a look at the second half of the GPGPU that contains the compute engines.