11.5.2 Further Reading

The reader can refer to advanced text books on computer architecture by Henessey and Patterson [Hennessy and Patterson, 2012], Kai Hwang [Hwang, 2003], and Jean Loup Baer [Baer, 2010] for a discussion on advanced memory systems. Specifically, the books discuss advanced techniques for prefetching, miss rate reduction, miss penalty reduction, and compiler directed approaches. The reader can also refer to the book on memory systems by Bruce Jacob [Jacob, 2009]. This book gives a comprehensive survey of most of the major techniques employed in designing state-of-the-art memory systems till 2009. The book by Balasubramaniam, Jouppi, and Muralimanohar on cache hierarchies also discusses some of the more advanced topics on the management of caches [Balasubramonian et al., 2011]. Managing the MMU is mostly studied in courses on operating systems [Tanenbaum, 2007, Silberschatz et al., 2008]. Research in DRAM memories [Mitra, 1999], and systems using advanced memory technologies is a hot topic of current research. A lot of research work is now focusing on phase change memories that do not require costly refresh cycles like DRAM. Readers can refer to the book by Qureshi, Gurumurthi, and Rajendran [Qureshi et al., 2011] for a thorough explanation of memory systems using phase

change memories.

Exercises

Overview

Ex. 1 — Define temporal locality, and spatial locality.

Ex. 2 — Experimentally verify that the log-normal distribution is a heavy-tailed distribution. What is the implication of a heavy tailed distribution in the context of the stack distance and temporal locality?

Ex. 3 — Define the term, address distance. Why do we find the nearest match in the last  accesses?

Ex. 4 — How do we take advantage of temporal locality in the memory system?

Ex. 5 — How do we take advantage of spatial locality in the memory system?

Caches and the Memory System

Ex. 6 — Consider a fully associative cache following the LRU replacement scheme and consisting of only 8 words. Consider the following sequence of memory accesses (the numbers denote the word address):   
20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 22, 30, 21, 23, 31

Assume that we begin when the cache is empty. What are the contents of the cache after the end of the sequence of memory accesses.

Ex. 7 — Answer Exercise 6 assuming a FIFO replacement scheme.

Ex. 8 — Consider a two-level cache using a write back policy. The L1 cache can store 2 words, and the L2 cache can store 4 words. Assume the caches to be fully associative (block  word); they follow the LRU replacement scheme. Consider the following sequence of memory accesses. The format of a write access is write <address> <value>, and the format of a read access is  .

write 20 200   
write 21 300   
write 22 400   
write 23 500   
write 20 201   
write 21 301   
read 22   
read 23

What are the contents of the caches at the end of the sequence of memory accesses? What are the contents of the caches, if we assume a write through policy ?

Ex. 9 — What is the total size (in bytes) of a direct mapped cache with the following configuration in a 32-bit system? It has a 10 bit index, and a block size of 64 bytes. Each block has 1 valid bit and 1 dirty bit.

Ex. 10 — Which sorting algorithm will have a better cache performance – bubble sort or selection sort? Explain your answer.

Ex. 11 — You have a cache with the following parameters: size :  bytes associativity :  block size :  bytes

Assuming a 32-bit address space, answer the following:

(a) What is the size of the tag in bits? (b) What is the size of the set index in bits?

\* Ex. 12 — Consider a direct mapped cache with 16 cache lines, indexed 0 to 15, where each cache line contains 32 integers (block size : 128 bytes).   
Consider a two-dimensional,  array of integers  . This array is laid out in memory such that  is next to  , and so on. Assume the cache is initially empty, and  maps to the first word of cache line 0.

Consider the following column-first traversal:

int sum = 0;   
for (int i = 0; i < 32; i++) { for( int j=0; j < 32; j++) { sum += a[i,j]; }   
}

and the following row-first traversal:

int sum = 0;   
for (int  ; i < 32; i++) { for( int j=0; j < 32; j++) { sum  a[j,i]; }   
}

Compare the number of cache misses produced by the two traversals, assuming the oldest cache line is evicted first. Assume that  ,  , and sum are stored in registers, and that no part of array  is saved in registers. It is always stored in the cache.

Ex. 13 — A processor has a baseline IPC of 1.5, an L1 miss rate of 5%, and an L2 miss rate of  . The hit time of the L1 cache is 1 cycle (part of the baseline IPC computation), the L2 hit time is 10 cycles, and the L2 miss penalty is 100 cycles. Compute the final IPC. Assume that all the miss rates are local miss rates.

The base CPI assumes that all the instructions hit in the L1 cache. Furthermore, assume that a third of the instructions are memory instructions. Write the formula for the average memory access time. What is the CPI of  ,  and  ?

 . 15 — Assume a cache that has  levels. For each level, the hit time is  cycles, and the local miss rate is  per cycle.

(a) What is the recursive formula for the average memory access time? (b) What is the average memory access time as  tends to  ?

\*\* Ex. 16 — Assume that you are given a machine with an unknown configuration. You need to find out a host of cache parameters by measuring the time it takes to execute different programs. These programs will be tailor-made in such a way that they will reveal something about the underlying system. For answering the set of questions, you need to broadly describe the approach. Assume that the cache follows the LRU scheme for replacement.

(a) How will you estimate the size of the L1 cache? (b) How will you estimate the L1 block size? (c) How will you estimate the L1 cache associativity?

Virtual Memory

Ex. 17 — In a 32-bit machine with a 4 KB page size, how many entries are there in a single level page table? What is the size of each entry in the page table in bits?

Ex. 18 — Consider a 32-bit machine with a 4 KB page size, and a two level page table. If we address the primary page table with 12 bits of the page address, then how many entries are there in each secondary page table?

Ex. 19 — In a two level page table, should we index the primary page table with the most significant bits of the page address, or the least significant bits? Explain your answer.

Ex. 20 — We have a producer-consumer interaction between processes  and  .  writes data that  reads in a shared space. However, B should never be allowed to write anything into that shared space. How can we implement this using paging? How do we ensure that B will never be able to write into the shared space?

Ex. 21 — Assume a process  , forks a process  . Forking a process means that  inherits a copy of  ’s entire address space. However, after the fork call, the address spaces are separate. How can we implement this using our paging mechanism?

Ex. 22 — How is creating a new thread different from a fork() operation in terms of memory addressing?

Ex. 23 — Most of the time, the new process generated by a fork call does not attempt to change or modify the data inherited from the parent process. So is it really necessary to copy all the frames of the parent process to the child process? Can you propose an optimization?

Ex. 24 — Explain the design of an inverted page table.

\* Ex. 25 — Calculate the expected value of the final CPI:

Baseline CPI: 1   
Percentage of memory accesses:    
TLB lookup time: 1 cycle (part of the baseline CPI)   
TLB miss rate:    
•Page table lookup time: 20 cycles (do not assume any page faults). Assume we can instantaneously insert entries into the TLB.   
L1 cache hit time: 1 cycle (Part of the baseline CPI)   
L1 local miss rate:    
L2 cache hit time: 20 cycles   
L2 local miss rate: 50%   
L2 miss penalty: 100 cycles

\*\* Ex. 26 — Most of the time, programmers use libraries of functions in their programs. These libraries contain functions for standard mathematical operations, for supporting I/O operations, and for interacting with the operating system. The machine instructions of these functions are a part of the final executable. Occasionally, programmers prefer to use dynamically linked libraries (DLLs). DLLs contain the machine code of specific functions. However, they are invoked at run time, and their machine code is not a part of the program executable. Propose a method to implement a method to load and unload DLLs with the help of virtual memory.

Design Problems

Ex. 27 — You need to learn to use the CACTI tool (http://www.hpl.hp.com/research/ cacti/) to estimate the area, latency, and power of different cache designs. Assume a 4-way associative 512 KB cache with 64 byte blocks. The baseline design has 1 read port, and 1 write port. You need to assume the baseline design, vary one parameter as mentioned below, and plot its relationship with the area, latency, or power consumption of a cache.

a)Plot the area versus the number of read ports.   
b)Plot the energy per read access versus the number of read ports.   
c)Plot the cache latency versus the associativity.   
d)Vary the size of the cache from 256 KB to 4 MB (powers of 2), and plot its relationship with area, latency, and power.

Ex. 28 — Write a cache simulator that accepts memory read/write requests and simulates the execution of a hierarchical system of caches.