[
    {
        "type": "text",
        "text": "10.1.3 Performance Benefits ",
        "text_level": 1,
        "page_idx": 415
    },
    {
        "type": "text",
        "text": "Let us quantify the expected benefit in terms of performance of a pipelined processor. We shall take a deeper look into performance issues in Section 10.9. Here, we shall look at this topic briefly. Let us assume that it takes $\\tau$ nanoseconds for an instruction to travel from the IF to RW stage of the pipeline in the worst case. The minimum value of the clock cycle is thus limited to $\\tau$ nanoseconds for the case of a single cycle pipeline. This is because in every clock cycle we need to ensure that an instruction executes completely. Alternatively, this mean that every $\\tau$ nanoseconds, we finish the execution of an instruction. ",
        "page_idx": 415
    },
    {
        "type": "text",
        "text": "Now, let us consider the case of a pipelined processor. Here, we have been assuming that the stages are balanced. This means that it takes the same amount of time to execute each stage. Most of the time, processor designers try to achieve this goal to the maximum extent that is possible. We can thus divide $\\tau$ by 5, and conclude that it takes $\\tau / 5$ nanoseconds to execute each stage. We can thus set the cycle time to $\\tau / 5$ . After the end of a cycle, the instructions in each stage of the pipeline proceed to the next stage. The instruction in the RW stage moves out of the pipeline and finished its execution. Simultaneously, a new instruction enters the IF stage. This is graphically shown in Figure 10.2. ",
        "page_idx": 415
    },
    {
        "type": "text",
        "text": "In the $n ^ { t h }$ cycle, we have five instructions (1-5) occupying the five stages of the pipeline. In the $( n + 1 ) ^ { t h }$ cycle each instruction progresses by 1 stage, and instruction 6 enters the pipeline. This pattern continues. ",
        "page_idx": 415
    },
    {
        "type": "text",
        "text": "The noteworthy point is that we are finishing the execution of a new instruction, every $\\tau / 5$ nanoseconds. As compared to a single-cycle processor that finishes the execution of a new instruction every $\\tau$ nanoseconds, the instruction throughput is 5 times higher for a pipelined processor. In a span of 1000 nanoseconds, a single cycle processor completes $1 0 0 0 / \\tau$ instructions, whereas a pipelined processor completes $5 0 0 0 / \\tau$ instructions, and is thus 5 times more efficient. Therefore, we observe a five-fold advantage with pipelining. ",
        "page_idx": 415
    },
    {
        "type": "image",
        "img_path": "images/c4d4c10000afedd38a9a9f19410ae62ec3531a01f7368fc9c4737504bd22511b.jpg",
        "img_caption": [
            "Figure 10.2: Instructions in the pipeline "
        ],
        "img_footnote": [],
        "page_idx": 416
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 416
    },
    {
        "type": "text",
        "text": "If we can obtain a five-fold advantage with a 5-stage pipeline, then by the same logic we should be able to obtain a 100-fold advantage with a 100-stage pipeline. In fact, we can keep on increasing the number of stages till a stage just contains one transistor. However, this is not the case, and there are fundamental limitations to the performance of a pipelined processor, as we shall show in the subsequent sections. It is not possible to arbitrarily increase the performance of a processor by increasing the number of pipeline stages. In fact, after a certain point, adding more stages is counterproductive. ",
        "page_idx": 416
    }
]