[
    {
        "type": "text",
        "text": "12.5.2 Software Interface ",
        "text_level": 1,
        "page_idx": 616
    },
    {
        "type": "text",
        "text": "Let us first consider the model of the machine. We need a set of vector registers. For example, the x86 SSE (Streaming SIMD Extensions) instruction set defines sixteen 128-bit registers (XMM0 . . . XMM15). Each such register can contain four integers, or four floating point values. Alternatively, it can also contain eight 2-byte short integers, or sixteen 1-byte characters. On the same lines, every vector ISA defines additional vector registers that are wider than normal registers. Typically, each register can contain multiple floating point values. Hence, in our SimpleRisc ISA, let us define eight 128-bit vector registers: vr0 . . . vr7. ",
        "page_idx": 616
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 617
    },
    {
        "type": "text",
        "text": "Now, we need instructions to load, store, and operate on vector registers. For loading vector registers, there are two options. We can either load values from contiguous memory locations, or from non-contiguous memory locations. The former case is more specific, and is typically suitable for array-based applications, where all the array elements are anyway stored in contiguous memory locations. Most vector extensions to ISAs support this variant of the load instruction because of its simplicity, and regularity. Let us try to design such a vector load instruction $v . l d$ for our SimpleRisc ISA. Let us consider the semantics shown in Table 12.4. Here, the $v . l d$ instruction reads in the contents of the memory locations ([r1+12], [r1+16], [r1+20], [r1 $^ +$ 24]) into the vector register vr1. In the table below note that $\\langle v r e g \\rangle$ is a vector register. ",
        "page_idx": 617
    },
    {
        "type": "table",
        "img_path": "images/dca424526bc799da0c80e95251aa3c18660cf55c1ee0bfb7bc044e83de8ad45d.jpg",
        "table_caption": [
            "Table 12.4: Semantics of the contiguous variant of the vector load instruction "
        ],
        "table_footnote": [],
        "table_body": "\n\n<html><body><table><tr><td>Example</td><td colspan=\"2\">Semantics</td><td colspan=\"4\">Explanation</td></tr><tr><td>v.ld vr1, 12[r1]</td><td>v.ld (vreg), (mem)</td><td></td><td>vr1\u2190</td><td></td><td>([r1+12],[r1+16],[r1+20],[r1+</td><td>24])</td></tr></table></body></html>\n\n",
        "page_idx": 617
    },
    {
        "type": "text",
        "text": "Now, let us consider the case of matrices. Let us consider a 10,000 element matrix, A[100][100], and assume that data is stored in row major order (see Section 3.2.2). Assume that we want to operate on two columns of the matrix. In this case, we have a problem because the elements in a column are not saved in contiguous locations. Hence, a vector load instruction that relies on the assumption that the input operands are saved in contiguous memory locations, will cease to work. We need to have dedicated support to fetch all the data for the locations in a column and save them in a vector register. Such an operation is known as a scatter-gather operation. This is because, the input operands are essentially scattered in main memory. We need to gather, and put them in one place, which is the vector register. Let us consider a scatter-gather variant of the vector load instruction, and call it v.sg.ld. Instead of making assumptions about the locations of the array elements, the processor reads another vector register that contains the addresses of the elements (semantics shown in Table 12.5). In this case, a dedicated vector load unit reads the memory addresses stored in vr2, fetches the corresponding values from memory, and writes them in sequence to the vector register, vr1. ",
        "page_idx": 617
    },
    {
        "type": "table",
        "img_path": "images/5daa77e18c52499ab4b1dcf58fbc1b3ce9aa9437b638e5928aade6c0156c8494.jpg",
        "table_caption": [
            "Table 12.5: Semantics of the non-contiguous variant of the vector load instruction "
        ],
        "table_footnote": [],
        "table_body": "\n\n<html><body><table><tr><td>Example</td><td>Semantics</td><td colspan=\"6\">Explanation</td></tr><tr><td>v.sg.ld vr1, vr2</td><td>v.sg.ld (vreg), (vreg)</td><td>vr1\u2190</td><td>(2[0]],r]\uff0c]</td><td></td><td></td><td></td><td></td><td>[3]])</td></tr></table></body></html>\n\n",
        "page_idx": 617
    },
    {
        "type": "text",
        "text": "Once, we have data loaded in vector registers, we can operate on two such registers directly. For example, if we consider 128-bit vector registers, vr1, and vr2. Then, the assembly statement v.add vr3, vr1, vr2, adds each pair of corresponding 4-byte floating point numbers stored in the input vector registers (vr1 and vr2), and stores the results in the relevant positions in the output vector register (vr3). Note that we use the vector add instruction $( v . a d d )$ here. We show an example of a vector add instruction in Figure 12.19. ",
        "page_idx": 617
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 618
    },
    {
        "type": "image",
        "img_path": "images/91ff5362eda657d212547023c207639870278c53b7bcc01a438be2b558684d32.jpg",
        "img_caption": [
            "Figure 12.19: Example of a vector addition "
        ],
        "img_footnote": [],
        "page_idx": 618
    },
    {
        "type": "text",
        "text": "Vector ISAs define similar operations for vector multiplication, division, and logical operations. Note that it is not necessary for a vector instruction to always have two input operands, which are vectors. We can multiply, a vector with a scalar, or we can have an instruction that operates on just one vector operand. For example, the SSE instruction set has dedicated instructions for computing trigonometric functions such as sin, and $c o s$ , for a set of floating point numbers packed in a vector register. If a vector instruction can simultaneously perform operations on $n$ operands, then we say that we have $n$ data lanes, and the vector instruction simultaneously performs an operation on all the $n$ data lanes. ",
        "page_idx": 618
    },
    {
        "type": "text",
        "text": "Definition 133 ",
        "text_level": 1,
        "page_idx": 618
    },
    {
        "type": "text",
        "text": "If a vector instruction can simultaneously perform operations on n operands, then we say that we have n data lanes, and the vector instruction simultaneously performs an operation on all the n data lanes. ",
        "page_idx": 618
    },
    {
        "type": "text",
        "text": "The last step is to store the vector register in memory. Here again, there are two options. We can either store to contiguous memory locations, which is simpler, or save to non-contiguous locations. We can design two variants of the vector store instruction (contiguous and noncontiguous) on the lines of the two variants of vector load instructions ( $v . l d$ and $v . s g . l d )$ . Sometimes it is necessary to introduce instructions that transfer data between scalar and vector registers. We shall not describe such instructions for the sake of brevity. We leave designing such instructions as an exercise for the reader. ",
        "page_idx": 618
    }
]