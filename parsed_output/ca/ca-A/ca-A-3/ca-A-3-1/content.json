[
    {
        "type": "text",
        "text": "A.3.1 Intel Atom ",
        "text_level": 1,
        "page_idx": 746
    },
    {
        "type": "text",
        "text": "Overview ",
        "text_level": 1,
        "page_idx": 746
    },
    {
        "type": "text",
        "text": "The Intel $\\textsuperscript { \\textregistered }$ Atom $\\textsuperscript { \\textregistered }$ processor started out with a unique set of requirements (see [Halfhill, 2008]). The designers had to design a core that was extremely power efficient, had enough features to run commercial operating systems and web browsers, and was fully x86 compatible. A naive approach to reduce power would have been to implement a subset of the x86 ISA. This approach would have led to a simpler and more power efficient decoder. Since the decoding logic is known to be power hungry in x86 processors, reducing its complexity is one of the simplest methods to reduce power. However, full x86 compatibility precluded this option. ",
        "page_idx": 746
    },
    {
        "type": "text",
        "text": "Hence, the designers were forced to consider novel designs that are extremely power efficient, and do not compromise on performance. Consequently, they decided to simplify the pipeline, and consider 2-issue inorder pipelines only. Recall from our discussion in Section 10.11.4 that out-of-order pipelines have complicated structures for finding the dependencies between instructions, and for executing them out of order. Some of these structures are the instruction window, renaming logic, scheduler, and wakeup-select logic. These structures add to the complexity of the processor, and increase its power dissipation. ",
        "page_idx": 746
    },
    {
        "type": "text",
        "text": "Secondly, most Intel processors typically translate CISC instructions into RISC like microops. These micro-ops execute like normal RISC instructions in the pipeline. The process of instruction translation consumes a lot of power. Hence, the designers of the Intel Atom decided to discard instruction translation. The Atom pipeline processes CISC instructions directly. For some instructions that are very complicated, the Atom processor does use a microcode ROM to translate them into simpler CISC instructions. However, this is more of an exception that the norm. ",
        "page_idx": 746
    },
    {
        "type": "image",
        "img_path": "images/73219f8c1c4a580865ad4348b69dfbfa4849d84a46bdd94170f545af4252109c.jpg",
        "img_caption": [
            "Figure A.9: The pipeline of the Intel Atom processor. ( $\\mathrm { A G } $ address generation) $\\textcircled { \\mathrm { c } } [ 2 0 0 8 ]$ The Linley Group. Adapted and reprinted, with permission. (Originally published in the Microprocessor Report. Source [Halfhill, 2008]) "
        ],
        "img_footnote": [],
        "page_idx": 746
    },
    {
        "type": "text",
        "text": "As compared to RISC processors, the fetch and decode stages are more complicated in CISC processors. This is because instructions have variable lengths, and demarcating instruction boundaries is a tedious process. Secondly, the process of decoding is also more complicated. Hence, Atom dedicates 6 stages out of its 16-stage pipeline to instruction fetch and decoding as shown in Figure A.9. The remaining stages perform the traditional functions of register file access, data cache access, and instruction execution. Along with the simpler pipeline, another hallmark feature of the Intel Atom processor is that it supports 2-way multithreading. Modern mobile devices typically run multitasking operating systems, and users run multiple programs at the same time. Multithreading can support this requirement, enable additional parallelism, and reduce idle time in processor pipelines. The last 3 stages in the pipeline are dedicated to handling exceptions, handling multithreading related events, and writing data back to register or memory. Like all modern processors, store instructions are not on the critical path. In general, processors that do not obey sequential consistency write their store values to a write buffer and proceed with executing subsequent instructions. ",
        "page_idx": 746
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 747
    },
    {
        "type": "text",
        "text": "Detailed Design ",
        "text_level": 1,
        "page_idx": 747
    },
    {
        "type": "image",
        "img_path": "images/b029c0272292213dd1f36a820d34877555ada8a17bb256a15d0a81f2d91ec1b8.jpg",
        "img_caption": [
            "Figure A.10: A block diagram of the Intel Atom processor $\\textcircled { \\mathrm { c } } [ 2 0 0 8 ]$ The Linley Group. Adapted and reprinted, with permission. (Originally published in the Microprocessor Report. Source [Halfhill, 2008]) "
        ],
        "img_footnote": [],
        "page_idx": 747
    },
    {
        "type": "text",
        "text": "Let us now describe the design in some more detail. Let us start with the fetch, and decode stages (see Figure A.10). In the fetch stage, the Atom processor predicts the direction and target of branches, and fetches a stream of bytes into the instruction prefetch buffers. The next task is to demarcate instructions in the fetched stream of bytes. Finding, the boundaries of x86 instructions is one of the most complicated tasks performed by this part of the pipeline. Consequently, the Atom processor has a 2 stage pre-decode step that adds 1-bit markers between instructions, after it decodes them for the first time. This step is performed by the ILD (instruction length decoder) unit It then saves the instructions in the i-cache. Subsequently, pre-decoded instructions fetched from the i-cache can bypass the pre-decoding step, and directly proceed to the decoding step because its length is already known. Saving these additional markers, reduces the effective size of the i-cache. The size of the i-cache is 36 KB; however, after adding the markers, it is effectively 32 KB. The decoder does not convert most CISC instructions into RISC like micro-ops. However, for some complicated x86 instructions, it is necessary to translate them into simpler micro-ops by accessing the microcode memory. ",
        "page_idx": 747
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 748
    },
    {
        "type": "text",
        "text": "Subsequently, integer instructions are dispatched to the integer execution units, and the FP instructions are dispatched to the FP execution units. Atom has two integer ALUs, two FP ALUs, and two address generation units for memory operations. For supporting multithreading, it is necessary to have two copies of the instruction queue (1 per thread), and two copies of the integer and FP register files. Instead of creating a copy of a hardware structure like an instruction queue, Intel follows a different approach. For example, in the Atom processor, the 32 entry instruction queue is split into two parts (with 16 entries each). Each thread uses its part of the instruction queue. ",
        "page_idx": 748
    },
    {
        "type": "text",
        "text": "Let us now discuss a general point about multithreading. Multithreading increases the utilization of resources on a chip by decreasing the time that they remain idle. Thus, a multithreaded processor is ideally expected to have a higher power overhead (because of higher activity), and also have better instruction throughput. It is important to note that unless a processor is designed wisely, the throughput might not predictably increase. Multithreading increases the contention in shared resources such as the caches, the TLBs, and the instruction schedule/dispatch logic. Especially, the caches get partitioned between the threads, and we expect the miss rates to increase. Similar is the case for the TLBs also. On the other hand, the pipeline need not remain idle in the shadow of an L2 miss or in low ILP (instruction level parallelism) phases of a program. Hence, there are pros and cons of multithreading, and we have performance benefits only when the good effects (performance increasing effects) outweigh the bad effects (contention increasing effects). ",
        "page_idx": 748
    }
]